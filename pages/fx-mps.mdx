# Generative Modeling of Foreign Exchange Rates with Matrix Product States

In the following project I am applying the Matrix Product State (MPS) training method from the paper Unsupervised Generative Modeling Using Matrix Product States [[1]](#references) to a financial dataset that consists of foreign exchange rates (FX). The code can be found in my [quantum-research](https://github.com/4d6174686973/quantum-research) github repository.

## Matrix Product States

Preparing content for:

- [ ] Tensor formulation
- [ ] MPS Visualization
- [ ] Sampling from MPS
- [ ] How to bring into Canonical form
- [ ] NLL Loss and Gradient

... work in progress

## Data Preprocessing

The dataset consists of four FX pairs: EURUSD, GBPUSD, USDCAD, USDJPY. In recent literature about generative modeling in finance, this dataset is a popular choice. [[2]](#references) For each of the four currencies we observe the daily mid price $P_i$. 

![Currencies](/currencies.png)

For preprocessing our dataset we first compute the log returns.

$L_i = log(\frac{P_{i+1}-P_i}{P_i}+1)$

The we substract the mean and divide by the standard deviation.

$S_i = \frac{L_i - \mu_L}{\sigma_L}$

The resulting series can be seen in belows plot.

![Log Returns](/log_returns.png)

Following histograms represent the marginal distributions of the target distribution that is objective to be learnt.

![Log Return Histograms](/log_ret_hists.png)

Since the Matrix Product State model only takes binary values we need to binarize our features. For that purpose the algorithm from [[2]](#references) is used.

To transfrom from real to binary we use

$x_{int} = \lfloor (2^N - 1) \frac{x-x_{min}}{x_{max}-x{min}} \rfloor \leftrightarrow x_{bin}$

To transform from binary to real we use

$x_{real}=x_{min} + (x_{int} \frac{x_{max}-x{min}}{2^N - 1})$

The binarized features represent the actual distribution that we are going to model. Ideally we could use a sufficient amount of bits per feature such that the target distributions could be rather closely recovered. In this experiment we limit ourselves to using f bits per feature to let the mps training finish in reasonable time, altough it is possible to scale up using more compute resources. 

![Binary Histograms](/binary_hists.png)

## MPS Training

During training the bond dimensions are adjusted from all 2 to [ 2  4  8 15 21 33 46 71 74 43 23 12  8  4  2  1].

The NLL Loss decreases sharply in the first five iterations and only changes minimal in all subsequent iterations.

![Loss](/loss.png)


## Results

For assessing how close the target distribution was actually modeled, we generate 1000 samples from the trained MPS with adjusted bond dimensions and compare them visually to the target marginal distributions.

![EURUSD Results](/EURUSD_result.png)
![GBPUSD Results](/GBPUSD_result.png)
![USDCAD Results](/USDCAD_result.png)
![USDJPY Results](/USDJPY_result.png)


## References

[1] Zhao-Yu Han, et al., Unsupervised Generative Modeling Using Matrix Product States, Phys. Rev. X 8, 031012, (17 July 2018). https://doi.org/10.1103/PhysRevX.8.031012 \
[2] Kondratyev, Oleksiy and Schwarz, Christian, The Market Generator (May 8, 2019). http://dx.doi.org/10.2139/ssrn.3384948 